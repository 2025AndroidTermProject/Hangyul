{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBMWA6SVgCbY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 모델 이름 설정\n",
        "model_name = \"hun3359/klue-bert-base-sentiment\"\n",
        "\n",
        "# 모델, 토크나이저, 설정 로드\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# 라벨 매핑 확인\n",
        "labels = [config.id2label[i] for i in range(len(config.id2label))]\n",
        "print(\"Labels:\", labels)\n",
        "\n",
        "# ✅ 1단계: 원본 모델 테스트\n",
        "def test_original_model(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
        "    logits = model(**inputs).logits\n",
        "    probs = tf.nn.softmax(logits, axis=-1).numpy()[0]\n",
        "    return logits.numpy()[0], probs\n",
        "\n",
        "# ✅ 2단계: 개선된 ConcreteFunction 정의\n",
        "@tf.function\n",
        "def model_inference(input_ids, attention_mask, token_type_ids=None):\n",
        "    # token_type_ids도 포함하여 더 안정적인 추론\n",
        "    if token_type_ids is not None:\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    else:\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    return outputs.logits\n",
        "\n",
        "# ✅ 3단계: 대표 데이터셋 생성 (양자화 개선)\n",
        "def representative_dataset():\n",
        "    \"\"\"대표 데이터셋 생성으로 양자화 품질 향상\"\"\"\n",
        "    sample_texts = [\n",
        "        \"오늘은 너무 행복한 하루야!\",\n",
        "        \"너무 피곤하고 지쳐.\",\n",
        "        \"오늘은 정말 뿌듯했어\",\n",
        "        \"평범한 하루였어\",\n",
        "        \"별로 좋지도 나쁘지도 않아\",\n",
        "        \"정말 최악의 하루였어\",\n",
        "        \"기분이 좋네요\",\n",
        "        \"화가 나는 일이 있었어\"\n",
        "    ]\n",
        "\n",
        "    for text in sample_texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"tf\", padding=\"max_length\",\n",
        "                          truncation=True, max_length=128)\n",
        "        # 올바른 데이터 타입으로 캐스팅 (int32 유지)\n",
        "        yield [\n",
        "            inputs['input_ids'],\n",
        "            inputs['attention_mask'],\n",
        "            inputs.get('token_type_ids', tf.zeros_like(inputs['input_ids']))\n",
        "        ]\n",
        "\n",
        "# ✅ 4단계: 개선된 TFLite 변환 (여러 시나리오)\n",
        "def convert_to_tflite_improved():\n",
        "    print(\"시나리오 1: 양자화 없이 변환 시도...\")\n",
        "    try:\n",
        "        # 구체적인 함수 생성\n",
        "        concrete_func = model_inference.get_concrete_function(\n",
        "            input_ids=tf.TensorSpec([1, 128], tf.int32, name=\"input_ids\"),\n",
        "            attention_mask=tf.TensorSpec([1, 128], tf.int32, name=\"attention_mask\"),\n",
        "            token_type_ids=tf.TensorSpec([1, 128], tf.int32, name=\"token_type_ids\")\n",
        "        )\n",
        "\n",
        "        # TFLite 변환기 설정 (양자화 없음)\n",
        "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        converter.allow_custom_ops = True\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "        print(\"✅ 양자화 없는 변환 성공!\")\n",
        "        return tflite_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 양자화 없는 변환 실패: {e}\")\n",
        "\n",
        "    print(\"\\n시나리오 2: 보수적 양자화로 변환 시도...\")\n",
        "    try:\n",
        "        # 구체적인 함수 생성\n",
        "        concrete_func = model_inference.get_concrete_function(\n",
        "            input_ids=tf.TensorSpec([1, 128], tf.int32, name=\"input_ids\"),\n",
        "            attention_mask=tf.TensorSpec([1, 128], tf.int32, name=\"attention_mask\"),\n",
        "            token_type_ids=tf.TensorSpec([1, 128], tf.int32, name=\"token_type_ids\")\n",
        "        )\n",
        "\n",
        "        # TFLite 변환기 설정\n",
        "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "        # 보수적 최적화 설정\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.representative_dataset = representative_dataset\n",
        "\n",
        "        # 타입 설정\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        converter.allow_custom_ops = True\n",
        "\n",
        "        # 양자화 타겟 설정 (가중치만 양자화)\n",
        "        converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "        print(\"✅ 보수적 양자화 변환 성공!\")\n",
        "        return tflite_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 보수적 양자화 변환 실패: {e}\")\n",
        "\n",
        "    print(\"\\n시나리오 3: 기본 변환만 시도...\")\n",
        "    try:\n",
        "        # 가장 기본적인 변환\n",
        "        concrete_func = model_inference.get_concrete_function(\n",
        "            input_ids=tf.TensorSpec([1, 128], tf.int32, name=\"input_ids\"),\n",
        "            attention_mask=tf.TensorSpec([1, 128], tf.int32, name=\"attention_mask\"),\n",
        "            token_type_ids=tf.TensorSpec([1, 128], tf.int32, name=\"token_type_ids\")\n",
        "        )\n",
        "\n",
        "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "        converter.allow_custom_ops = True\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "        print(\"✅ 기본 변환 성공!\")\n",
        "        return tflite_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 기본 변환도 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "# ✅ 5단계: TFLite 모델 테스트\n",
        "def test_tflite_model(tflite_model, text):\n",
        "    \"\"\"TFLite 모델 테스트\"\"\"\n",
        "    # 인터프리터 생성\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # 입력/출력 세부사항 가져오기\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    print(\"Input details:\", input_details)\n",
        "    print(\"Output details:\", output_details)\n",
        "\n",
        "    # 텍스트 토큰화\n",
        "    inputs = tokenizer(text, return_tensors=\"np\", padding=\"max_length\",\n",
        "                      truncation=True, max_length=128)\n",
        "\n",
        "    # 입력 설정\n",
        "    for i, detail in enumerate(input_details):\n",
        "        if 'input_ids' in detail['name']:\n",
        "            interpreter.set_tensor(detail['index'], inputs['input_ids'].astype(np.int32))\n",
        "        elif 'attention_mask' in detail['name']:\n",
        "            interpreter.set_tensor(detail['index'], inputs['attention_mask'].astype(np.int32))\n",
        "        elif 'token_type_ids' in detail['name']:\n",
        "            token_type_ids = inputs.get('token_type_ids', np.zeros_like(inputs['input_ids']))\n",
        "            interpreter.set_tensor(detail['index'], token_type_ids.astype(np.int32))\n",
        "\n",
        "    # 추론 실행\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # 결과 가져오기\n",
        "    logits = interpreter.get_tensor(output_details[0]['index'])\n",
        "    probs = tf.nn.softmax(logits, axis=-1).numpy()[0]\n",
        "\n",
        "    return logits[0], probs\n",
        "\n",
        "# ✅ 6단계: 전체 테스트 실행\n",
        "def run_comparison_test():\n",
        "    test_texts = [\n",
        "        \"오늘은 너무 행복한 하루야!\",\n",
        "        \"너무 피곤하고 지쳐.\",\n",
        "        \"오늘은 정말 뿌듯했어\",\n",
        "        \"평범한 하루였어\"\n",
        "    ]\n",
        "\n",
        "    print(\"TFLite 모델 변환 중...\")\n",
        "    tflite_model = convert_to_tflite_improved()\n",
        "\n",
        "    if tflite_model is None:\n",
        "        print(\"TFLite 변환 실패!\")\n",
        "        return\n",
        "\n",
        "    print(\"모델 변환 완료! 비교 테스트 시작...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for text in test_texts:\n",
        "        print(f\"\\n테스트 텍스트: '{text}'\")\n",
        "\n",
        "        # 원본 모델 결과\n",
        "        orig_logits, orig_probs = test_original_model(text)\n",
        "        orig_pred = labels[np.argmax(orig_probs)]\n",
        "        print(f\"원본 모델: {orig_pred} ({orig_probs.max():.3f})\")\n",
        "\n",
        "        # TFLite 모델 결과\n",
        "        try:\n",
        "            tflite_logits, tflite_probs = test_tflite_model(tflite_model, text)\n",
        "            tflite_pred = labels[np.argmax(tflite_probs)]\n",
        "            print(f\"TFLite 모델: {tflite_pred} ({tflite_probs.max():.3f})\")\n",
        "\n",
        "            # 차이 분석\n",
        "            logits_diff = np.abs(orig_logits - tflite_logits).mean()\n",
        "            probs_diff = np.abs(orig_probs - tflite_probs).mean()\n",
        "            print(f\"로짓 차이: {logits_diff:.4f}, 확률 차이: {probs_diff:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"TFLite 테스트 실패: {e}\")\n",
        "\n",
        "    # 모델 저장\n",
        "    tflite_path = \"sentiment_model_improved.tflite\"\n",
        "    with open(tflite_path, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"\\n개선된 모델 저장됨: {tflite_path}\")\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    run_comparison_test()\n",
        "\n"
      ]
    }
  ]
}